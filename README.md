# SLURM_RAY

üëâ[Full documentation](https://www.henri-jamet.com/docs/slurmray/slurm-ray/)

## Description

**SlurmRay** is a module for effortlessly distributing tasks on a [Slurm](https://slurm.schedmd.com/) cluster using the [Ray](https://ray.io/) library. **SlurmRay** was initially designed to work with the [Curnagl](https://wiki.unil.ch/ci/books/high-performance-computing-hpc/page/curnagl) cluster at the *University of Lausanne*. However, it should be able to run on any [Slurm](https://slurm.schedmd.com/) cluster with a minimum of configuration.

## Installation

**SlurmRay** is designed to run both locally and on a cluster without any modification. This design is intended to allow work to be carried out on a local machine until the script seems to be working. It should then be possible to run it using all the resources of the cluster without having to modify the code.

```bash
pip install slurmray
```

## Usage

```python
from slurmray.RayLauncher import RayLauncher
import ray
import torch

def function_inside_function():
    with open("slurmray/RayLauncher.py", "r") as f:
        return f.read()[0:10]

def example_func(x):
    result = (
        ray.cluster_resources(),
        f"GPU is available : {torch.cuda.is_available()}",
        x + 1,
        function_inside_function(),
    )
    return result

launcher = RayLauncher(
    project_name="example", # Name of the project (will create a directory with this name in the current directory)
    func=example_func, # Function to execute
    args={"x": 1}, # Arguments of the function
    files=["slurmray/RayLauncher.py"], # List of files to push to the cluster (file path will be recreated on the cluster)
    modules=[], # List of modules to load on the curnagl Cluster (CUDA & CUDNN are automatically added if use_gpu=True)
    node_nbr=1, # Number of nodes to use
    use_gpu=True, # If you need A100 GPU, you can set it to True
    memory=8, # In MegaBytes
    max_running_time=5, # In minutes
    runtime_env={"env_vars": {"NCCL_SOCKET_IFNAME": "eno1"}}, # Example of environment variable
    server_run=True, # To run the code on the cluster and not locally
    server_ssh="curnagl.dcsr.unil.ch", # Address of the SLURM server
    server_username="hjamet", # Username to connect to the server
    server_password=None, # Will be asked in the terminal
)

result = launcher()
print(result)
```

## Tests

The project includes simple "hello world" tests to quickly validate that SLURM_RAY works correctly after major modifications. These tests can be executed directly or via pytest.

### Running tests directly

```bash
# Test CPU
poetry run python tests/test_hello_world_cpu.py

# Test GPU
poetry run python tests/test_hello_world_gpu.py
```

### Running tests with pytest

```bash
# Run all tests
poetry run pytest tests/

# Run specific test
poetry run pytest tests/test_hello_world_cpu.py
poetry run pytest tests/test_hello_world_gpu.py
```

The tests require credentials for the cluster. You can provide them via a `.env` file with `CURNAGL_USERNAME` and `CURNAGL_PASSWORD`, or they will be prompted interactively.

## Publishing to PyPI

This project uses [Poetry](https://python-poetry.org/) for package management and publishing. Follow these steps to publish a new version to PyPI:

### 1. Update the version

Increment the version in `pyproject.toml` according to the type of change:

```bash
# Automatic version bumping
poetry version patch   # 3.6.4 -> 3.6.5 (bugfix)
poetry version minor   # 3.6.4 -> 3.7.0 (new feature)
poetry version major   # 3.6.4 -> 4.0.0 (breaking change)
```

Or manually edit the `version` field in `pyproject.toml`.

### 2. Build the package

```bash
poetry build
```

This creates distribution files in the `dist/` directory:
- `slurmray-{version}.tar.gz` (source distribution)
- `slurmray-{version}-py3-none-any.whl` (wheel)

### 3. Configure PyPI credentials

**First-time setup:**

1. Create an API token on [PyPI](https://pypi.org/manage/account/token/)
2. Configure Poetry to use the token:

```bash
poetry config pypi-token.pypi your-token-here
```

**Alternative:** Poetry will prompt for credentials during publishing. Use `__token__` as username and your API token as password.

### 4. Publish to PyPI

**Production (PyPI):**

```bash
poetry publish
```

**Testing (TestPyPI):**

To test the publishing process without affecting production:

```bash
poetry publish --repository testpypi
```

### Pre-publication checklist

Before publishing, ensure:

- [ ] Version incremented in `pyproject.toml`
- [ ] All tests pass (`poetry run pytest tests/`)
- [ ] README.md is up to date
- [ ] Code tested locally
- [ ] `poetry build` completes without errors
- [ ] PyPI credentials configured

### Quick reference

```bash
# Complete publishing workflow
poetry version patch          # Update version
poetry build                  # Build package
poetry publish                # Publish to PyPI

# Optional: test on TestPyPI first
poetry publish --repository testpypi
```

**Important notes:**

- Each version must be unique on PyPI (versions cannot be overwritten)
- TestPyPI is useful for testing the publishing process
- Consider creating a Git tag after publishing:
  ```bash
  git tag v3.6.5
  git push origin v3.6.5
  ```

## Launcher documentation

The Launcher documentation is available [here](https://htmlpreview.github.io/?https://raw.githubusercontent.com/hjamet/SLURM_RAY/main/documentation/RayLauncher.html).

# Roadmap

| T√¢che | Objectif | √âtat | D√©pendances |
|-------|----------|------|-------------|
| **Corriger les incompatibilit√©s avec Curnagl** | Analyser et corriger les incompatibilit√©s entre le code actuel et la documentation Curnagl actuelle. Cette t√¢che implique la v√©rification et l'ajustement des versions Python utilis√©es, l'identification et la correction des modules charg√©s via `module load`, la mise √† jour des arguments SLURM qui pourraient √™tre d√©pr√©ci√©s, et la validation des partitions disponibles sur le cluster. L'objectif est de garantir que le code fonctionne correctement avec l'environnement Curnagl actuel, en s'assurant que toutes les d√©pendances syst√®me sont compatibles et que les jobs peuvent √™tre soumis et ex√©cut√©s sans erreur. Cette √©tape est fondamentale avant toute √©volution majeure du code. | üèóÔ∏è En cours | - |
| **Corriger et rediriger automatiquement le dashboard Ray vers local** | Corriger le bug de configuration du dashboard dans RayLauncher.py (ligne 199) qui emp√™che le lancement correct du dashboard Ray. Une fois le bug corrig√©, impl√©menter une redirection automatique du dashboard Ray vers la machine locale via port forwarding SSH. Le syst√®me doit √©tablir un tunnel SSH automatiquement lorsque le job d√©marre, permettant l'acc√®s au dashboard sur `http://localhost:8888` pendant l'ex√©cution du job. Cette fonctionnalit√© am√©liore significativement l'exp√©rience utilisateur en permettant un monitoring en temps r√©el des ressources et de l'√©tat des t√¢ches Ray sans n√©cessiter de configuration manuelle de tunnels SSH. | üèóÔ∏è En cours | - |
| **Int√©grer l'ouverture automatique du dashboard Ray** | Int√©grer l'ouverture automatique du dashboard Ray dans l'interface interactive de gestion des jobs SLURM cr√©√©e pr√©c√©demment. Cette fonctionnalit√© doit permettre d'ouvrir le dashboard en local (http://localhost:8888) avec gestion automatique du port forwarding SSH si n√©cessaire. L'utilisateur doit pouvoir s√©lectionner un job en cours d'ex√©cution depuis l'interface CLI et avoir le dashboard qui s'ouvre automatiquement dans son navigateur, avec le tunnel SSH √©tabli en arri√®re-plan. Cela simplifie grandement l'acc√®s aux m√©triques de performance pour l'utilisateur final. | üìÖ √Ä faire | - |
| **Am√©liorer la gestion des credentials (username/password) via .env** | Modifier RayLauncher pour charger automatiquement `server_username` et `server_password` depuis un fichier `.env` local, tout en gardant la r√©trocompatibilit√© avec les param√®tres explicites pass√©s au constructeur. Le syst√®me doit d'abord v√©rifier les variables d'environnement (via `python-dotenv`), puis les param√®tres explicites, et enfin demander interactivement si aucun n'est trouv√©. Cette am√©lioration am√©liore la s√©curit√© (√©vite de hardcoder les mots de passe) et l'ergonomie pour les utilisateurs fr√©quents qui peuvent stocker leurs credentials de mani√®re s√©curis√©e dans un fichier `.env` ignor√© par Git. | üìÖ √Ä faire | - |
| **Optimiser la gestion du stockage et le nettoyage des fichiers** | Optimiser la gestion du stockage et du nettoyage pour am√©liorer les performances globales du syst√®me. Impl√©menter un cache intelligent pour r√©utiliser le virtualenv entre ex√©cutions si les d√©pendances n'ont pas chang√©, √©vitant ainsi de recr√©er l'environnement √† chaque fois. Nettoyer syst√©matiquement les fichiers temporaires apr√®s t√©l√©chargement r√©ussi des r√©sultats pour √©viter l'accumulation de donn√©es inutiles. Optimiser la g√©n√©ration de `requirements.txt` pour qu'elle soit plus rapide et plus pr√©cise. Corriger les incoh√©rences potentielles de versions Python entre l'environnement local et distant pour garantir la compatibilit√©. | üìÖ √Ä faire | Corriger les incompatibilit√©s avec Curnagl |
| **Refactoring Architecture Strategy** | Refactoriser l'architecture du projet pour introduire le Design Pattern "Strategy" afin de pr√©parer le support multi-backend. Cr√©er une classe abstraite `ClusterBackend` d√©finissant l'interface commune (m√©thodes `submit`, `status`, `cancel`, `get_logs`, etc.), puis encapsuler toute la logique SLURM actuelle dans une classe concr√®te `SlurmBackend` qui impl√©mente cette interface. Cette √©tape est cruciale pour permettre l'ajout futur du backend "Desi" sans complexifier le code avec des conditions multiples. Le refactoring doit √™tre effectu√© sans r√©gression, en s'assurant que toutes les fonctionnalit√©s existantes continuent de fonctionner exactement comme avant. | üìÖ √Ä faire | Corriger les incompatibilit√©s avec Curnagl |
| **Tester le package SLURM_RAY sur CPU et GPU** | Cr√©er et ex√©cuter des tests fonctionnels complets pour v√©rifier que le package fonctionne correctement avec des fonctions simples sur CPU et/ou GPU via Ray sur un cluster SLURM. Ces tests doivent √™tre des "smoke tests" qui valident la cha√Æne compl√®te : soumission du job, ex√©cution sur le cluster, r√©cup√©ration des r√©sultats. Les tests doivent √™tre rapides √† ex√©cuter et permettre de valider rapidement que le syst√®me fonctionne correctement apr√®s chaque modification majeure. Ils serviront de garde-fou pour √©viter les r√©gressions lors des √©volutions futures du code. | üìÖ √Ä faire | Corriger les incompatibilit√©s avec Curnagl, Optimiser la gestion du stockage et le nettoyage des fichiers |
| **Impl√©mentation Backend Desi** | Impl√©menter le backend Desi (SSH/SFTP) avec ex√©cution Ray isol√©e et gestion des ports dynamiques pour le support multi-utilisateurs. Ce backend doit g√©rer une ex√©cution "stateless" via SSH/SFTP : cr√©ation d'un dossier temporaire unique par job sur le serveur distant, upload du code s√©rialis√© et des d√©pendances, ex√©cution d'un script "runner" distant qui lance une instance Ray isol√©e avec des ports dynamiques pour √©viter les conflits entre utilisateurs, r√©cup√©ration des r√©sultats, et suppression imp√©rative du dossier temporaire (nettoyage fail-fast) pour ne pas polluer le serveur partag√©. | üìÖ √Ä faire | Refactoring Architecture Strategy |
| **Unification et Arguments** | Unifier l'interface RayLauncher pour g√©rer proprement les deux backends (SLURM et Desi) et adapter la validation des arguments. Mettre √† jour la classe principale `RayLauncher` (le Context du pattern Strategy) pour instancier dynamiquement le bon backend selon un argument `cluster='curnagl'` ou `cluster='desi'`. Impl√©menter une validation des arguments conditionnelle : avertir si des arguments sp√©cifiques √† SLURM (partitions, time_limit) sont pass√©s en mode Desi, et adapter la gestion de la demande de GPU (`use_gpu`) pour qu'elle fonctionne correctement avec le backend Desi. | üìÖ √Ä faire | Impl√©mentation Backend Desi |
| **Rebranding et Documentation** | Mettre √† jour la documentation et les m√©tadonn√©es pour officialiser le support DESI @ HEC UNIL. Actualiser le README, les docstrings et les m√©tadonn√©es PyPI pour documenter clairement les deux modes d'ex√©cution (Curnagl/SLURM et Desi/SSH), les pr√©-requis respectifs, et fournir des exemples d'utilisation adapt√©s aux nouveaux utilisateurs du d√©partement. Cette t√¢che inclut √©galement la mise √† jour de l'identit√© visuelle du projet pour refl√©ter son nouveau statut d'outil officiel du d√©partement. | üìÖ √Ä faire | Unification et Arguments |
| **Mettre √† jour la documentation pour tout avoir dans le repo** | Remplacer les liens externes dans README.md par du contenu local, int√©grer la documentation de RayLauncher directement dans le repository pour √©viter les d√©pendances vers des sites externes. Migrer toute la documentation externe (liens actuels vers sites tiers ou HTML pr√©visualis√©s) directement dans le d√©p√¥t (dossier `docs/` ou Markdown). L'objectif est que le repository soit auto-suffisant et que la documentation versionn√©e suive l'√©volution du code. Cela garantit que la documentation est toujours √† jour et accessible m√™me si les sites externes changent ou disparaissent. | üìÖ √Ä faire | Tester le package SLURM_RAY sur CPU et GPU, Am√©liorer la gestion des credentials (username/password) via .env, Corriger les incompatibilit√©s avec Curnagl, Rebranding et Documentation |
