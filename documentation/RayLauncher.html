<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>RayLauncher API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>RayLauncher</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from typing import Any, Callable, List
import subprocess
import sys
import time
import os
import dill


class RayLauncher:
    &#34;&#34;&#34;A class that automatically connects RAY workers and executes the function requested by the user&#34;&#34;&#34;

    def __init__(
        self,
        project_name: str = None,
        func: Callable = None,
        args: dict = None,
        modules: List[str] = [],
        node_nbr: int = 1,
        use_gpu: bool = False,
        memory: int = 64,
        max_running_time: int = 60,
    ):
        &#34;&#34;&#34;Initialize the launcher

        Args:
            project_name (str, optional): Name of the project. Defaults to None.
            func (Callable, optional): Function to execute. This function should not be remote but can use ray ressources. Defaults to None.
            args (dict, optional): Arguments of the function. Defaults to None.
            modules (List[str], optional): List of modules to load on the curnagl Cluster. Use `module spider` to see available modules. Defaults to None.
            node_nbr (int, optional): Number of nodes to use. Defaults to 1.
            use_gpu (bool, optional): Use GPU or not. Defaults to False.
            memory (int, optional): Amount of RAM to use per node in GigaBytes. Defaults to 64.
            max_running_time (int, optional): Maximum running time of the job in minutes. Defaults to 60.
        &#34;&#34;&#34;
        # Check the parameters
        if project_name is None:
            raise ValueError(&#34;project_name cannot be None&#34;)
        if func is None:
            raise ValueError(&#34;func cannot be None&#34;)
        if not callable(func):
            raise ValueError(&#34;func must be callable&#34;)
        if args is None:
            args = {}
        if not isinstance(args, dict):
            raise ValueError(&#34;args must be a dict&#34;)
        if not isinstance(modules, list):
            raise ValueError(&#34;modules must be a list&#34;)
        if not isinstance(node_nbr, int):
            raise ValueError(&#34;node_nbr must be an int&#34;)
        if not isinstance(use_gpu, int):
            raise ValueError(&#34;gpu_nbr must be an int&#34;)
        if not isinstance(memory, int):
            raise ValueError(&#34;memory must be an int&#34;)
        if not isinstance(max_running_time, int):
            raise ValueError(&#34;max_running_time must be an int&#34;)
        
        # Save the parameters
        self.project_name = project_name
        self.func = func
        self.args = args
        self.node_nbr = node_nbr
        self.use_gpu = use_gpu
        self.memory = memory
        self.max_running_time = max_running_time

        self.modules = [&#34;gcc&#34;, &#34;python/3.9.13&#34;] + [
            mod for mod in modules if mod not in [&#34;gcc&#34;, &#34;python/3.9.13&#34;]
        ]
        if self.use_gpu is True and &#34;cuda&#34; not in self.modules:
            self.modules += [&#34;cuda/11.8.0&#34;, &#34;cudnn&#34;]

        # Check if this code is running on a cluster
        self.cluster = os.path.exists(&#34;/usr/bin/sbatch&#34;)

        # Create the project directory if not exists
        self.pwd_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), &#34;..&#34;)
        self.project_path = os.path.join(self.pwd_path, &#34;logs&#34;, self.project_name)
        if not os.path.exists(self.project_path):
            os.makedirs(self.project_path)

        # Write the python script
        self.__write_python_script(self.func, self.args)

        # Write the sh script
        self.script_file, self.job_name = self.__write_slurm_script()

    def __call__(self, cancel_old_jobs: bool = True) -&gt; Any:
        &#34;&#34;&#34;Launch the job and return the result

        Args:
            cancel_old_jobs (bool, optional): Cancel the old jobs. Defaults to True.

        Returns:
            Any: Result of the function
        &#34;&#34;&#34;

        if self.cluster:
            print(&#34;Cluster detected, running on cluster...&#34;)
            # Cancel the old jobs
            if cancel_old_jobs:
                print(&#34;Canceling old jobs...&#34;)
                subprocess.Popen(
                    [&#34;scancel&#34;, &#34;-u&#34;, os.environ[&#34;USER&#34;]],
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE,
                )

            # Launch the job
            self.__launch_job(self.script_file, self.job_name)

        else:
            print(&#34;No cluster detected, running locally...&#34;)
            subprocess.Popen(
                [sys.executable, os.path.join(self.project_path, &#34;spython.py&#34;)]
            )

        # Load the result
        while not os.path.exists(os.path.join(self.project_path, &#34;result.pkl&#34;)):
            time.sleep(0.25)
        with open(os.path.join(self.project_path, &#34;result.pkl&#34;), &#34;rb&#34;) as f:
            result = dill.load(f)

        return result

    def __write_python_script(self, func: Callable = None, args: list = None):
        &#34;&#34;&#34;Write the python script that will be executed by the job

        Args:
            func (Callable, optional): Function to execute. Defaults to None.
            args (list, optional): Arguments of the function. Defaults to None.

        Raises:
            ValueError: If the function is not callable
        &#34;&#34;&#34;
        print(&#34;Writing python script...&#34;)

        # Remove the old python script
        for file in os.listdir(self.project_path):
            if file.endswith(&#34;.py&#34;) or file.endswith(&#34;.pkl&#34;):
                os.remove(os.path.join(self.project_path, file))

        # Pickle the function
        with open(os.path.join(self.project_path, &#34;func.pkl&#34;), &#34;wb&#34;) as f:
            dill.dump(func, f)

        # Pickle the arguments
        if args is None:
            args = {}
        with open(os.path.join(self.project_path, &#34;args.pkl&#34;), &#34;wb&#34;) as f:
            dill.dump(args, f)

        # Write the python script
        with open(os.path.join(self.pwd_path, &#34;slurmray&#34;, &#34;assets&#34;, &#34;spython_template.py&#34;), &#34;r&#34;) as f:
            text = f.read()

        text = text.replace(&#34;{{PROJECT_PATH}}&#34;, f&#39;&#34;{self.project_path}&#34;&#39;)
        text = text.replace(
            &#34;{{LOCAL_MODE}}&#34;,
            str(
                f&#34;&#34;
                if not self.cluster
                else &#34;\n\taddress=&#39;auto&#39;\n\tinclude_dashboard=True,\n\tdashboard_host=&#39;0.0.0.0&#39;,\n\tdashboard_port=8888,\n&#34;
            ) + &#34;num_gpus=1&#34; if self.use_gpu is True else &#34;&#34;,
        )
        with open(os.path.join(self.project_path, &#34;spython.py&#34;), &#34;w&#34;) as f:
            f.write(text)

    def __write_slurm_script(
        self,
    ):
        &#34;&#34;&#34;Write the slurm script that will be executed by the job

        Returns:
            str: Name of the script file
            str: Name of the job
        &#34;&#34;&#34;
        print(&#34;Writing slurm script...&#34;)
        template_file = os.path.join(self.pwd_path, &#34;slurmray&#34;, &#34;assets&#34;, &#34;sbatch_template.sh&#34;)

        JOB_NAME = &#34;{{JOB_NAME}}&#34;
        NUM_NODES = &#34;{{NUM_NODES}}&#34;
        MEMORY = &#34;{{MEMORY}}&#34;
        RUNNING_TIME = &#34;{{RUNNING_TIME}}&#34;
        PARTITION_NAME = &#34;{{PARTITION_NAME}}&#34;
        COMMAND_PLACEHOLDER = &#34;{{COMMAND_PLACEHOLDER}}&#34;
        GIVEN_NODE = &#34;{{GIVEN_NODE}}&#34;
        COMMAND_SUFFIX = &#34;{{COMMAND_SUFFIX}}&#34;
        LOAD_ENV = &#34;{{LOAD_ENV}}&#34;
        PARTITION_SPECIFICS = &#34;{{PARTITION_SPECIFICS}}&#34;

        job_name = &#34;{}_{}&#34;.format(
            self.project_name, time.strftime(&#34;%d%m-%Hh%M&#34;, time.localtime())
        )

        # Convert the time to xx:xx:xx format
        max_time = &#34;{}:{}:{}&#34;.format(
            str(self.max_running_time // 60).zfill(2),
            str(self.max_running_time % 60).zfill(2),
            str(0).zfill(2),
        )

        # ===== Modified the template script =====
        with open(template_file, &#34;r&#34;) as f:
            text = f.read()
        text = text.replace(JOB_NAME, os.path.join(self.project_path, job_name))
        text = text.replace(NUM_NODES, str(self.node_nbr))
        text = text.replace(MEMORY, str(self.memory))
        text = text.replace(RUNNING_TIME, str(max_time))
        text = text.replace(PARTITION_NAME, str(&#34;gpu&#34; if self.use_gpu &gt; 0 else &#34;cpu&#34;))
        text = text.replace(
            COMMAND_PLACEHOLDER, str(f&#34;{sys.executable} {self.project_path}/spython.py&#34;)
        )
        text = text.replace(LOAD_ENV, str(f&#34;module load {&#39; &#39;.join(self.modules)}&#34;))
        text = text.replace(GIVEN_NODE, &#34;&#34;)
        text = text.replace(COMMAND_SUFFIX, &#34;&#34;)
        text = text.replace(
            &#34;# THIS FILE IS A TEMPLATE AND IT SHOULD NOT BE DEPLOYED TO &#34; &#34;PRODUCTION!&#34;,
            &#34;# THIS FILE IS MODIFIED AUTOMATICALLY FROM TEMPLATE AND SHOULD BE &#34;
            &#34;RUNNABLE!&#34;,
        )

        # ===== Add partition specifics =====
        if self.use_gpu &gt; 0:
            text = text.replace(
                PARTITION_SPECIFICS,
                str(&#34;#SBATCH --gres gpu:1\n#SBATCH --gres-flags enforce-binding&#34;),
            )
        else:
            text = text.replace(PARTITION_SPECIFICS, &#34;#SBATCH --exclusive&#34;)

        # ===== Save the script =====
        script_file = &#34;sbatch.sh&#34;
        with open(os.path.join(self.project_path, script_file), &#34;w&#34;) as f:
            f.write(text)

        return script_file, job_name

    def __launch_job(self, script_file: str = None, job_name: str = None):
        &#34;&#34;&#34;Launch the job

        Args:
            script_file (str, optional): Name of the script file. Defaults to None.
            job_name (str, optional): Name of the job. Defaults to None.
        &#34;&#34;&#34;
        # ===== Submit the job =====
        print(&#34;Start to submit job!&#34;)
        subprocess.Popen([&#34;sbatch&#34;, os.path.join(self.project_path, script_file)])
        print(
            &#34;Job submitted! Script file is at: &lt;{}&gt;. Log file is at: &lt;{}&gt;&#34;.format(
                os.path.join(self.project_path, script_file),
                os.path.join(self.project_path, &#34;{}.log&#34;.format(job_name)),
            )
        )

        # Wait for log file to be created
        current_queue = None
        while True:
            time.sleep(0.25)
            if os.path.exists(
                os.path.join(self.project_path, &#34;{}.log&#34;.format(job_name))
            ):
                break
            else:
                # Get result from squeue -p {{PARTITION_NAME}}
                result = subprocess.run(
                    [&#34;squeue&#34;, &#34;-p&#34;, &#34;gpu&#34; if self.use_gpu is True else &#34;cpu&#34;],
                    capture_output=True,
                )
                df = result.stdout.decode(&#34;utf-8&#34;).split(&#34;\n&#34;)
                users = list(
                    map(
                        lambda row: row[: len(df[0].split(&#34;ST&#34;)[0])][:-1].split(&#34; &#34;)[
                            -1
                        ],
                        df,
                    )
                )
                status = list(
                    map(
                        lambda row: row[len(df[0].split(&#34;ST&#34;)[0]) :]
                        .strip()
                        .split(&#34; &#34;)[0],
                        df,
                    )
                )
                nodes = list(
                    map(
                        lambda row: row[len(df[0].split(&#34;NODE&#34;)[0]) :]
                        .strip()
                        .split(&#34; &#34;)[0],
                        df,
                    )
                )
                node_list = list(
                    map(lambda row: row[len(df[0].split(&#34;NODELIST(REASON)&#34;)[0]) :], df)
                )

                to_queue = list(
                    zip(
                        users,
                        status,
                        nodes,
                        node_list,
                    )
                )[1:]
                if current_queue is None or current_queue != to_queue:
                    current_queue = to_queue
                    print(&#34;Current queue:&#34;)
                    # Tabulared print
                    format_row = &#34;{:&gt;30}&#34; * (len(current_queue[0]))
                    for user, status, nodes, node_list in current_queue:
                        print(format_row.format(user, status, nodes, node_list))
                    print()

        # Wait for the job to finish while printing the log
        log_cursor_position = 0
        job_finished = False
        while not job_finished:
            time.sleep(0.25)
            if os.path.exists(os.path.join(self.project_path, &#34;result.pkl&#34;)):
                job_finished = True
            else:
                with open(
                    os.path.join(self.project_path, &#34;{}.log&#34;.format(job_name)), &#34;r&#34;
                ) as f:
                    f.seek(log_cursor_position)
                    text = f.read()
                    if text != &#34;&#34;:
                        print(text, end=&#34;&#34;)
                    log_cursor_position = f.tell()

        print(&#34;Job finished!&#34;)



# ---------------------------------------------------------------------------- #
#                             EXAMPLE OF EXECUTION                             #
# ---------------------------------------------------------------------------- #
if __name__ == &#34;__main__&#34;:
    import ray

    def example_func(x):
        return ray.cluster_resources(), x + 1

    launcher = RayLauncher(
        project_name=&#34;example&#34;,
        func=example_func,
        args={&#34;x&#34;: 1},
        modules=[],
        node_nbr=1,
        use_gpu=True,
        memory=64,
        max_running_time=15,
    )

    result = launcher()
    print(result)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="RayLauncher.RayLauncher"><code class="flex name class">
<span>class <span class="ident">RayLauncher</span></span>
<span>(</span><span>project_name: str = None, func: Callable = None, args: dict = None, modules: List[str] = [], node_nbr: int = 1, use_gpu: bool = False, memory: int = 64, max_running_time: int = 60)</span>
</code></dt>
<dd>
<div class="desc"><p>A class that automatically connects RAY workers and executes the function requested by the user</p>
<p>Initialize the launcher</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>project_name</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Name of the project. Defaults to None.</dd>
<dt><strong><code>func</code></strong> :&ensp;<code>Callable</code>, optional</dt>
<dd>Function to execute. This function should not be remote but can use ray ressources. Defaults to None.</dd>
<dt><strong><code>args</code></strong> :&ensp;<code>dict</code>, optional</dt>
<dd>Arguments of the function. Defaults to None.</dd>
<dt><strong><code>modules</code></strong> :&ensp;<code>List[str]</code>, optional</dt>
<dd>List of modules to load on the curnagl Cluster. Use <code>module spider</code> to see available modules. Defaults to None.</dd>
<dt><strong><code>node_nbr</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Number of nodes to use. Defaults to 1.</dd>
<dt><strong><code>use_gpu</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Use GPU or not. Defaults to False.</dd>
<dt><strong><code>memory</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Amount of RAM to use per node in GigaBytes. Defaults to 64.</dd>
<dt><strong><code>max_running_time</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Maximum running time of the job in minutes. Defaults to 60.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class RayLauncher:
    &#34;&#34;&#34;A class that automatically connects RAY workers and executes the function requested by the user&#34;&#34;&#34;

    def __init__(
        self,
        project_name: str = None,
        func: Callable = None,
        args: dict = None,
        modules: List[str] = [],
        node_nbr: int = 1,
        use_gpu: bool = False,
        memory: int = 64,
        max_running_time: int = 60,
    ):
        &#34;&#34;&#34;Initialize the launcher

        Args:
            project_name (str, optional): Name of the project. Defaults to None.
            func (Callable, optional): Function to execute. This function should not be remote but can use ray ressources. Defaults to None.
            args (dict, optional): Arguments of the function. Defaults to None.
            modules (List[str], optional): List of modules to load on the curnagl Cluster. Use `module spider` to see available modules. Defaults to None.
            node_nbr (int, optional): Number of nodes to use. Defaults to 1.
            use_gpu (bool, optional): Use GPU or not. Defaults to False.
            memory (int, optional): Amount of RAM to use per node in GigaBytes. Defaults to 64.
            max_running_time (int, optional): Maximum running time of the job in minutes. Defaults to 60.
        &#34;&#34;&#34;
        # Check the parameters
        if project_name is None:
            raise ValueError(&#34;project_name cannot be None&#34;)
        if func is None:
            raise ValueError(&#34;func cannot be None&#34;)
        if not callable(func):
            raise ValueError(&#34;func must be callable&#34;)
        if args is None:
            args = {}
        if not isinstance(args, dict):
            raise ValueError(&#34;args must be a dict&#34;)
        if not isinstance(modules, list):
            raise ValueError(&#34;modules must be a list&#34;)
        if not isinstance(node_nbr, int):
            raise ValueError(&#34;node_nbr must be an int&#34;)
        if not isinstance(use_gpu, int):
            raise ValueError(&#34;gpu_nbr must be an int&#34;)
        if not isinstance(memory, int):
            raise ValueError(&#34;memory must be an int&#34;)
        if not isinstance(max_running_time, int):
            raise ValueError(&#34;max_running_time must be an int&#34;)
        
        # Save the parameters
        self.project_name = project_name
        self.func = func
        self.args = args
        self.node_nbr = node_nbr
        self.use_gpu = use_gpu
        self.memory = memory
        self.max_running_time = max_running_time

        self.modules = [&#34;gcc&#34;, &#34;python/3.9.13&#34;] + [
            mod for mod in modules if mod not in [&#34;gcc&#34;, &#34;python/3.9.13&#34;]
        ]
        if self.use_gpu is True and &#34;cuda&#34; not in self.modules:
            self.modules += [&#34;cuda/11.8.0&#34;, &#34;cudnn&#34;]

        # Check if this code is running on a cluster
        self.cluster = os.path.exists(&#34;/usr/bin/sbatch&#34;)

        # Create the project directory if not exists
        self.pwd_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), &#34;..&#34;)
        self.project_path = os.path.join(self.pwd_path, &#34;logs&#34;, self.project_name)
        if not os.path.exists(self.project_path):
            os.makedirs(self.project_path)

        # Write the python script
        self.__write_python_script(self.func, self.args)

        # Write the sh script
        self.script_file, self.job_name = self.__write_slurm_script()

    def __call__(self, cancel_old_jobs: bool = True) -&gt; Any:
        &#34;&#34;&#34;Launch the job and return the result

        Args:
            cancel_old_jobs (bool, optional): Cancel the old jobs. Defaults to True.

        Returns:
            Any: Result of the function
        &#34;&#34;&#34;

        if self.cluster:
            print(&#34;Cluster detected, running on cluster...&#34;)
            # Cancel the old jobs
            if cancel_old_jobs:
                print(&#34;Canceling old jobs...&#34;)
                subprocess.Popen(
                    [&#34;scancel&#34;, &#34;-u&#34;, os.environ[&#34;USER&#34;]],
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE,
                )

            # Launch the job
            self.__launch_job(self.script_file, self.job_name)

        else:
            print(&#34;No cluster detected, running locally...&#34;)
            subprocess.Popen(
                [sys.executable, os.path.join(self.project_path, &#34;spython.py&#34;)]
            )

        # Load the result
        while not os.path.exists(os.path.join(self.project_path, &#34;result.pkl&#34;)):
            time.sleep(0.25)
        with open(os.path.join(self.project_path, &#34;result.pkl&#34;), &#34;rb&#34;) as f:
            result = dill.load(f)

        return result

    def __write_python_script(self, func: Callable = None, args: list = None):
        &#34;&#34;&#34;Write the python script that will be executed by the job

        Args:
            func (Callable, optional): Function to execute. Defaults to None.
            args (list, optional): Arguments of the function. Defaults to None.

        Raises:
            ValueError: If the function is not callable
        &#34;&#34;&#34;
        print(&#34;Writing python script...&#34;)

        # Remove the old python script
        for file in os.listdir(self.project_path):
            if file.endswith(&#34;.py&#34;) or file.endswith(&#34;.pkl&#34;):
                os.remove(os.path.join(self.project_path, file))

        # Pickle the function
        with open(os.path.join(self.project_path, &#34;func.pkl&#34;), &#34;wb&#34;) as f:
            dill.dump(func, f)

        # Pickle the arguments
        if args is None:
            args = {}
        with open(os.path.join(self.project_path, &#34;args.pkl&#34;), &#34;wb&#34;) as f:
            dill.dump(args, f)

        # Write the python script
        with open(os.path.join(self.pwd_path, &#34;slurmray&#34;, &#34;assets&#34;, &#34;spython_template.py&#34;), &#34;r&#34;) as f:
            text = f.read()

        text = text.replace(&#34;{{PROJECT_PATH}}&#34;, f&#39;&#34;{self.project_path}&#34;&#39;)
        text = text.replace(
            &#34;{{LOCAL_MODE}}&#34;,
            str(
                f&#34;&#34;
                if not self.cluster
                else &#34;\n\taddress=&#39;auto&#39;\n\tinclude_dashboard=True,\n\tdashboard_host=&#39;0.0.0.0&#39;,\n\tdashboard_port=8888,\n&#34;
            ) + &#34;num_gpus=1&#34; if self.use_gpu is True else &#34;&#34;,
        )
        with open(os.path.join(self.project_path, &#34;spython.py&#34;), &#34;w&#34;) as f:
            f.write(text)

    def __write_slurm_script(
        self,
    ):
        &#34;&#34;&#34;Write the slurm script that will be executed by the job

        Returns:
            str: Name of the script file
            str: Name of the job
        &#34;&#34;&#34;
        print(&#34;Writing slurm script...&#34;)
        template_file = os.path.join(self.pwd_path, &#34;slurmray&#34;, &#34;assets&#34;, &#34;sbatch_template.sh&#34;)

        JOB_NAME = &#34;{{JOB_NAME}}&#34;
        NUM_NODES = &#34;{{NUM_NODES}}&#34;
        MEMORY = &#34;{{MEMORY}}&#34;
        RUNNING_TIME = &#34;{{RUNNING_TIME}}&#34;
        PARTITION_NAME = &#34;{{PARTITION_NAME}}&#34;
        COMMAND_PLACEHOLDER = &#34;{{COMMAND_PLACEHOLDER}}&#34;
        GIVEN_NODE = &#34;{{GIVEN_NODE}}&#34;
        COMMAND_SUFFIX = &#34;{{COMMAND_SUFFIX}}&#34;
        LOAD_ENV = &#34;{{LOAD_ENV}}&#34;
        PARTITION_SPECIFICS = &#34;{{PARTITION_SPECIFICS}}&#34;

        job_name = &#34;{}_{}&#34;.format(
            self.project_name, time.strftime(&#34;%d%m-%Hh%M&#34;, time.localtime())
        )

        # Convert the time to xx:xx:xx format
        max_time = &#34;{}:{}:{}&#34;.format(
            str(self.max_running_time // 60).zfill(2),
            str(self.max_running_time % 60).zfill(2),
            str(0).zfill(2),
        )

        # ===== Modified the template script =====
        with open(template_file, &#34;r&#34;) as f:
            text = f.read()
        text = text.replace(JOB_NAME, os.path.join(self.project_path, job_name))
        text = text.replace(NUM_NODES, str(self.node_nbr))
        text = text.replace(MEMORY, str(self.memory))
        text = text.replace(RUNNING_TIME, str(max_time))
        text = text.replace(PARTITION_NAME, str(&#34;gpu&#34; if self.use_gpu &gt; 0 else &#34;cpu&#34;))
        text = text.replace(
            COMMAND_PLACEHOLDER, str(f&#34;{sys.executable} {self.project_path}/spython.py&#34;)
        )
        text = text.replace(LOAD_ENV, str(f&#34;module load {&#39; &#39;.join(self.modules)}&#34;))
        text = text.replace(GIVEN_NODE, &#34;&#34;)
        text = text.replace(COMMAND_SUFFIX, &#34;&#34;)
        text = text.replace(
            &#34;# THIS FILE IS A TEMPLATE AND IT SHOULD NOT BE DEPLOYED TO &#34; &#34;PRODUCTION!&#34;,
            &#34;# THIS FILE IS MODIFIED AUTOMATICALLY FROM TEMPLATE AND SHOULD BE &#34;
            &#34;RUNNABLE!&#34;,
        )

        # ===== Add partition specifics =====
        if self.use_gpu &gt; 0:
            text = text.replace(
                PARTITION_SPECIFICS,
                str(&#34;#SBATCH --gres gpu:1\n#SBATCH --gres-flags enforce-binding&#34;),
            )
        else:
            text = text.replace(PARTITION_SPECIFICS, &#34;#SBATCH --exclusive&#34;)

        # ===== Save the script =====
        script_file = &#34;sbatch.sh&#34;
        with open(os.path.join(self.project_path, script_file), &#34;w&#34;) as f:
            f.write(text)

        return script_file, job_name

    def __launch_job(self, script_file: str = None, job_name: str = None):
        &#34;&#34;&#34;Launch the job

        Args:
            script_file (str, optional): Name of the script file. Defaults to None.
            job_name (str, optional): Name of the job. Defaults to None.
        &#34;&#34;&#34;
        # ===== Submit the job =====
        print(&#34;Start to submit job!&#34;)
        subprocess.Popen([&#34;sbatch&#34;, os.path.join(self.project_path, script_file)])
        print(
            &#34;Job submitted! Script file is at: &lt;{}&gt;. Log file is at: &lt;{}&gt;&#34;.format(
                os.path.join(self.project_path, script_file),
                os.path.join(self.project_path, &#34;{}.log&#34;.format(job_name)),
            )
        )

        # Wait for log file to be created
        current_queue = None
        while True:
            time.sleep(0.25)
            if os.path.exists(
                os.path.join(self.project_path, &#34;{}.log&#34;.format(job_name))
            ):
                break
            else:
                # Get result from squeue -p {{PARTITION_NAME}}
                result = subprocess.run(
                    [&#34;squeue&#34;, &#34;-p&#34;, &#34;gpu&#34; if self.use_gpu is True else &#34;cpu&#34;],
                    capture_output=True,
                )
                df = result.stdout.decode(&#34;utf-8&#34;).split(&#34;\n&#34;)
                users = list(
                    map(
                        lambda row: row[: len(df[0].split(&#34;ST&#34;)[0])][:-1].split(&#34; &#34;)[
                            -1
                        ],
                        df,
                    )
                )
                status = list(
                    map(
                        lambda row: row[len(df[0].split(&#34;ST&#34;)[0]) :]
                        .strip()
                        .split(&#34; &#34;)[0],
                        df,
                    )
                )
                nodes = list(
                    map(
                        lambda row: row[len(df[0].split(&#34;NODE&#34;)[0]) :]
                        .strip()
                        .split(&#34; &#34;)[0],
                        df,
                    )
                )
                node_list = list(
                    map(lambda row: row[len(df[0].split(&#34;NODELIST(REASON)&#34;)[0]) :], df)
                )

                to_queue = list(
                    zip(
                        users,
                        status,
                        nodes,
                        node_list,
                    )
                )[1:]
                if current_queue is None or current_queue != to_queue:
                    current_queue = to_queue
                    print(&#34;Current queue:&#34;)
                    # Tabulared print
                    format_row = &#34;{:&gt;30}&#34; * (len(current_queue[0]))
                    for user, status, nodes, node_list in current_queue:
                        print(format_row.format(user, status, nodes, node_list))
                    print()

        # Wait for the job to finish while printing the log
        log_cursor_position = 0
        job_finished = False
        while not job_finished:
            time.sleep(0.25)
            if os.path.exists(os.path.join(self.project_path, &#34;result.pkl&#34;)):
                job_finished = True
            else:
                with open(
                    os.path.join(self.project_path, &#34;{}.log&#34;.format(job_name)), &#34;r&#34;
                ) as f:
                    f.seek(log_cursor_position)
                    text = f.read()
                    if text != &#34;&#34;:
                        print(text, end=&#34;&#34;)
                    log_cursor_position = f.tell()

        print(&#34;Job finished!&#34;)</code></pre>
</details>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="RayLauncher.RayLauncher" href="#RayLauncher.RayLauncher">RayLauncher</a></code></h4>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>